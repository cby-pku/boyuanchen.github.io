---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am a junior undergraduate majoring in Artificial Intelligence at Yuanpei College, [Peking University](https://english.pku.edu.cn/). 

I am fortunate to be advised by Professor [Yaodong Yang](https://www.yangyaodong.com/) at the Institute for AI, Peking University.

My research interests cover Alignment and Interaction (e.g., Scalable Oversight, which is essential to the safety of advanced AI systems). I'm also interested in Game Theory and Multi-Agent Systems. My current research focuses on the goal of constructing safe and trustworthy AI systems. You can find my research statement [here](https://cby-pku.github.io//files/research_statement.pdf).

My answer to the [Hamming question](https://www.cs.virginia.edu/~robins/YouAndYourResearch.html) (â€œWhat are the most important problems [that you should probably work on]?â€): 
<ul>
<li>How to align systems smarter than humans and how to align them on tasks challenging for human evaluation? (<i>i.e.</i>, <b>scalable oversight</b>)</li>
<li>How can we integrate theory and experimental validation to embed moral values into AI systems? (<i>e.g.</i>, <b>moral reflection</b> and <b>moral progress</b>) and address the AI alignment problem from a <b>socio-technical</b> perspective.</li>
</ul> 

I have just started on this long road, and I will leverage my youth and curiosity to seize more opportunities and time for an in-depth exploration of these problems.

News
======
- (06/2024)ğŸ‰ We introduce the [PKU-SafeRLHF dataset](https://sites.google.com/view/pku-saferlhf), designed to promote research on safety alignment in LLMs.
- (06/2024)ğŸ™ï¸ Happy to introduce our new work about *elasticity* of LLMs. Click [here](https://arxiv.org/abs/2406.06144) for further details.
- (04/2024)ğŸŠ Our work - [BeaverTails](https://github.com/PKU-Alignment/beavertails) has been recognized by [Meta](https://llama.meta.com/trust-and-safety), further contributing to AI safety research.
- (03/2024)ğŸ’¥ Our alignment survey has been recognized by [NIST](https://www.nist.gov/)! [More details](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.pdf?utm_source=danielmiessler.com&utm_medium=newsletter&utm_campaign=ul-no-415-it-s-raining-9-cves-40-job-loss-from-ai-invisible-prompt-injection).
- (03/2024)ğŸš€ We have made significant updates to the [alignment survey](https://alignmentsurvey.com/) (V4)!
- (02/2024)ğŸ’¥ We release [Aligner](https://arxiv.org/abs/2402.02416): **a new efficient alignment paradigm, bypasses the whole RLHF process.**
- (11/2023)ğŸ™ï¸ I am honored to give [a talk](https://www.bilibili.com/video/BV1rj411L7XH/?spm_id_from=333.999.0.0&vd_source=b1ff6dcfa0111e176021e49d4a0ee142) about our alignment survey!
- (11/2023)ğŸš€ We release [AI Alignment Survey](https://arxiv.org/abs/2310.19852) and [Alignment Resource Website](https://alignmentsurvey.com/). Welcome to further discussion!

Publications
======
- **(Under Review) Language Models Resist Alignment**
  <br/>
  _Jiaming Ji\*, Kaile Wang\*, Tianyi Qiu\*, **Boyuan Chen\***, Jiayi Zhou, Changye Li, Hantao Lou, and Yaodong Yang_
  <br/>
  ğŸ“„[[Paper](https://arxiv.org/abs/2406.06144)]
- **(Under Review) Aligner: Achieving Efficient Alignment through Weak-to-Strong Correction**
  <br/>
  _Jiaming Ji\*, **Boyuan Chen\***, Hantao Lou, Donghai Hong, Borong Zhang, Xuehai Pan, Juntao Dai, and Yaodong Yang_
  <br/>
  ğŸ“„[[Paper](https://arxiv.org/abs/2402.02416)]
  ğŸŒ[[Website](https://aligner2024.github.io/)]
  ğŸŒŸ[[Media](https://mp.weixin.qq.com/s/O9PP4Oc_Ee3R_HxKyd31Qg)]
- **(Under Review) PKU-SafeRLHF: A Safety Alignment Preference Dataset for Llama Family Models**
  <br/>
  ğŸ¤—[[Dataset](https://huggingface.co/datasets/PKU-Alignment/PKU-SafeRLHF)]
  ğŸŒ[[Website](https://sites.google.com/view/pku-saferlhf)]
- **(Under Review) Efficient Model-agnostic Alignment via Bayesian Persuasion**
  <br/>
  ğŸ“„[[Paper](https://arxiv.org/abs/2406.06144)]
- **(Preprint) AI Alignment: A Comprehensive Survey**
  <br/>
  _Jiaming Ji\*,Tianyi Qiu\*,**Boyuan Chen\***,Borong Zhang\*,Hantao Lou,Kaile Wang,Yawen Duan,Zhonghao He,Jiayi Zhou,Zhaowei Zhang,Fanzhi Zeng,Kwan Yee Ng,Juntao Dai,Xuehai Pan,Aidan Oâ€™Gara,Yingshan Lei,Hua Xu,Brian Tse,[Jie Fu](https://bigaidream.github.io/),[Stephen McAleer](https://www.andrew.cmu.edu/user/smcaleer/),[Yaodong Yang](https://www.yangyaodong.com/),[Yizhou Wang](https://cfcs.pku.edu.cn/english/people/faculty/yizhouwang/index.htm),[Song-Chun Zhu](https://zhusongchun.net/),[Yike Guo](https://cse.hkust.edu.hk/admin/people/faculty/profile/yikeguo),and [Wen Gao](https://idm.pku.edu.cn/info/1017/1041.htm)_
  <br/>
  ğŸ“„[[Paper](https://arxiv.org/abs/2310.19852)]
  ğŸŒ[[Website](https://alignmentsurvey.com/)]
  ğŸ¥[[Video](https://www.bilibili.com/video/BV1rj411L7XH/?spm_id_from=333.999.0.0&vd_source=b1ff6dcfa0111e176021e49d4a0ee142)]
  ğŸŒŸ[[PKU-Alignment Group](https://github.com/PKU-Alignment)]

- **(NeurIPS 2023) BEAVERTAILS: Towards Improved Safety Alignment of LLM via a Human-Preference Dataset**
  <br/>
  _Jiaming Ji\*, Mickel Liu\*, Juntao Dai\*, Xuehai Pan, Chi Zhang, Ce Bian, **Boyuan Chen**, Ruiyang Sun, Yizhou Wang, Yaodong Yang_
  <br/>
  ğŸ“„[[Paper](https://openreview.net/pdf?id=g0QovXbFw3)]
  ğŸŒ[[Website](https://sites.google.com/view/pku-beavertails)]

Experiences
======
- [Tong Class](https://tongclass.ac.cn/about/), Peking University(PKU)
  <br/>
  Undergraduate Student 
  <br/>
  September. 2022 â€“ Present
  
- [PAIR Lab: PKU Alignment and Interaction Research Lab](https://pair-lab.com/)
  <br/>
  Research Intern (advisor: Prof. [Yaodong Yang](https://www.yangyaodong.com/) at [Institute for AI, Peking University](https://www.ai.pku.edu.cn/))
  <br/>
  May. 2023 â€“ Present

Selected Awards
======
- 2024: SenseTime Scholarship (25/year in China, 1/25, Â¥20000 RMB)
- 2024: Yicong Huang Scholarship (research innovation award, Â¥8000 RMB)
- 2024: Research Excellence Award (Â¥5000 RMB)
- 2024: Ching-Ling Soong Future Scholarship (Â¥5000 RMB)
- 2023: Yicong Huang Scholarship (Â¥8000 RMB)
- 2023: Peking University Third Prize Scholarship (Â¥4000 RMB)
- 2023: Peking University Public Service Scholarship (Â¥2000 RMB)
- 2022: Peking University Freshman Scholarship (Â¥10000 RMB)

<a href='https://clustrmaps.com/site/1c03m'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=600&t=n&d=SyBiJ1Ugb-rc6fbLUU-lVXiLkH4XSENzuYg767o06-o&co=2d78ad&ct=ffffff'/></a>
